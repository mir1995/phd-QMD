\document[./main_hagedorn.tex]{subfiles}
\usepackage{amsmath}

\begin{document}
\subsection{Semiclassical dynamics}
\subsubsection{Quadratic potential}
Consider a one level TDSE with a quadratic potential 
$V(\bm{x})$ and $\varphi_k^{\epsilon}[\Pi]$ as initial condition, 
for some $k \in \mathbb{N}^d$. 
Then, Hagedorn showed that the solution is fully described in 
terms of a system of ordinary differential equations for the parameter set $\Pi$,
that is
\begin{align}
  \dot{\bm{q}} &= \bm{p}
    \label{hagedorn:hagedorn_dynamics:parameters:evolution:q}
    \\
  \dot{\bm{p}} &=-\nabla V(\bm{q})
    \label{hagedorn:hagedorn_dynamics:parameters:evolution:p}
    \\
  \dot{\bm{P}} &=-\nabla^2 V(\bm{q})\bm{Q}
    \label{hagedorn:hagedorn_dynamics:parameters:evolution:P}
    \\
    \dot{\bm{Q}} &= \bm{P}
    \label{hagedorn:hagedorn_dynamics:parameters:evolution:Q}
    \\
    S(t) &= \int_0^t \frac{|\bm{p}(s)|^2}{2} - V(\bm{q}(s))  ds
    \label{hagedorn:hagedorn_dynamics:parameters:evolution:S}
    %\label{Hagedorn:quadratic:q:p}
\end{align}
where $e^{-\frac{i}{\epsilon}S(t)}$ is a multiplicative global phase 
factor.
\textcolor{red}{To do: understand the equation of motion and descripe what 
happens from a qualitative perspective.}
\\\\
\textcolor{red}{Can it be proven using Baker-Campbell-Hausdorf formula? First for 
$\varphi_0$ and then generally using the properties of the raising and lowering 
operators as in..[reference].}
\\
Since 
   $ \left[
      -\frac{\epsilon^2}{2} \Delta, V
    \right]
    =
    \frac{\epsilon^2}{2} \Delta (V)
    = 
    \frac{\epsilon^2}{2} c 
  $
  where $c \in \mathbb{R}$, the Baker-Campbell-Hausdorf formula yields 
  \begin{equation}
    \begin{split}
      \varphi_{0}(x,t) &= e^{-\frac{i}{\epsilon}t H } \varphi_{0}(x,0) 
      \\
      &=
      e^{i\frac{\epsilon}{2}t \Delta} e^{-\frac{i}{\epsilon}tV} e^{i\frac{\epsilon}{4}t c} \varphi_{0}(x,0)
      \\
      &= \cdots
    \end{split}
  \end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
% CUBIC POTENTIALS 
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Cubic potentials}
Why can we not modify the system of ODEs describing the evolution of the 
parameter set $\Pi$ such that the result also holds for cubic potentials? 
If we think of what would happen if we had a tunnelling situation, then the 
tunnelled wavepacket would have to be described by a different set of parameters 
or even a different linear combination of Hagedorn wavepackets. 
\textcolor{red}{this is an informal answer.} But perhaps there is a modification 
if the potential is a polynomial of only even degrees, but this will not be very useful
from a practical perspective.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
% NON-QUADRATIC POTENTIALS: DIRAC-FRENKEL VARIATIONAL APPROXIMATION 
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Non-quadratic potentials}
\textcolor{red}{I have chosen perhaps the 
non standard convention of conjugating the second entry which will entail having to 
put the basis vectors in the second entry when doing the projection, I think the convention 
is to conjugate the first entry - to check}
\\
\\
Let $W(x)$ denote the non-quadratic term of the potential and consider a linear 
combination of Hagedorn wavepackets as initial condition, that is 
$\psi(x,0) = \sum_{k \in \mathcal{K}} c_k \varphi_k^\epsilon[\Pi]$ subject 
to $\sum_{k \in \mathcal{K}} |c_k|^2 = 1$. 
Since $W(x) \not = 0$, we seek an approximate solution 
$\psi_{\mathcal{K}}(x,t) := e^{\frac{i}{\epsilon}S(t)}\sum_{k \in \mathcal{K}} c_k(t) \varphi_k^\epsilon[\Pi]$
such that the residual between the exact solution $\psi(x,t)$ and 
$\psi_{\mathcal{K}}(x,t) \in span(\{\varphi_k\}_{k \in \mathcal{K}})$ is minimised
(see the illustration in Figure ...).
In \cite{lubichQuantumClassicalMolecular2008} this is formalised via the so-called 
Dirac-Frenkel variational approximation principle which results in finding 
$\frac{d}{dt}c_k$ such that
\textcolor{red}{projecting the residual on the time derivative would be a weaker 
requirement - you can be orthogonal to a line in a plane but not to the all plane. and 
we want to be orthogonal to the all subspace since we are already using those 
basis sets}
\begin{equation}
  \begin{split}
  \left\langle 
    -\frac{i}{\epsilon} H \psi_{\mathcal{K}} - \partial_t \psi_{\mathcal{K}} , \varphi_{k} 
  \right\rangle  = 0 \hspace{1cm} 
\forall \text{ } k \in \mathcal{K}
  \end{split}
\end{equation}
Expanding the above equation we have 
\begin{equation}
  \begin{split}
    \sum_{l \in \mathcal{K}} 
    \left\langle 
      - \frac{i}{\epsilon} H c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l - \partial_t (c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l)
      , \varphi_k
    \right\rangle
    = 0
  \end{split}
\end{equation}
and since 
\begin{equation}
  \begin{split}
    H c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l 
    &=
    (H - W) (c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l) +
    W (c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l)
  \\
    \partial_t (c_l e^{\frac{i}{\epsilon}S(t)} \varphi_l)
    &=
    \dot{c_l} e^{\frac{i}{\epsilon}S(t)} \varphi_l 
    - c_l\frac{i}{\epsilon}  (H - W)e^{\frac{i}{\epsilon}S(t)} \varphi_l 
  \end{split}
\end{equation}
by the orthonormality property of the Hagedorn wavepackets we have 
\begin{equation}
  \begin{split}
    \dot{c}_l
    =
    \sum_{l \in \mathcal{K}} 
    - \frac{i}{\epsilon} c_l
    \left\langle 
        W \varphi_l, \varphi_k 
    \right\rangle
  \end{split}
\end{equation}
so that
$\bm{c}(t) := (c_k(t))_{k \in \mathcal{K}}$ 
satisfy the following differential equation 
\begin{align}
  i\epsilon  \bm{\dot c}(t) &= 
  \bm{F}(t)\bm{c}(t)
  \label{hagedorn:hagedorn_dynamics:coefficient:matrix}
\end{align}
with $\bm{F}_{kl}(t) = \langle W \varphi_l, \varphi_k \rangle  
= \overline{\bm{F}_{lk}}$.
\\
\textcolor{blue}{comment on the kind of system you obtained above intuitively and 
how you would go about solving it efficiently. What are the properties of the 
block matrix F}
%\subfile{hag_frenkel_projection}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIRAC FRENKEL PROJECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{tikzpicture}[scale=1.7]
  \centering
  \coordinate (A) at (1.8,-0.2);
  \coordinate (P) at (1.5,1.1);

  \draw (0:2cm)   arc[radius=2cm,start angle=0,end angle=180]
        (210:2cm) arc[radius=2cm,start angle=210,end angle=330];
  \draw (180:2cm) arc[x radius=2cm, y radius=0.5cm, start angle=180,end angle=360];

  \draw [dashed] (210:2cm)
        arc[start angle=210,delta angle=-30,radius=2cm]
        arc[start angle=180,delta angle=-180,x radius=2cm,y radius=0.5cm]
        arc[start angle=0,delta angle=-30,radius=2cm];

  %\draw [dashed] (80:2cm and 0.5cm) -- (260:2cm and 0.5cm);
  \draw [dashed] (150:2cm) coordinate(ul) -- (30:2cm) coordinate(ur);

  \draw (-4.5,-1) -- (3.5,-1) -- (4.5,1) node[anchor=south east] 
    {\Large $ \operatorname{span}(\{\Phi_{k}\}_{k \in \mathcal{K}}) \subset \mathcal{L}^2$} -- (ur) (ul) -- (-3.5,1) -- (-4.5,-1);

  %\draw [dashed] (A) -- (P) coordinate[pos=0.47](B);
  \path (A) node[circle, fill, inner sep=3pt, label=below:{\hspace{2cm} \Large$ \psi(x,0) $}]{};
  %\path (B) node[circle, fill, inner sep=1pt, label=left:{\scriptsize$ (\xi,\eta,\zeta) $}]{};
  %\path (P) node[circle, fill, inner sep=2pt, label=above:{ }]{};
  \def\rad{1cm}
  \begin{scope}[xslant=1.6,yslant=-0.6,yshift=30,xshift=55, scale=0.3]
\filldraw[fill=gray!10,opacity=0.4]
  (-4,1) -- (3,1) -- (3,-1) -- (-4,-1) -- cycle;
\end{scope}
  %\draw [dashed] (-2,0) -- (2,0);
%\path[use as bounding box] ([yshift=-8mm]current axis.south west) rectangle (current axis.north east);
\end{tikzpicture}
\end{center}
\textcolor{red}{Would the approximation then have necessarily smaller norm...? 
only if you do the projection and do not increment the number of basis functions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIRAC FRENKEL PROJECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

I suppose one would diagonalise $\bm{F}$ since it is a 
symmetric matrix and obtain a fully decoupled system. 
\textcolor{red}{So what is this Kryloc space about - see Lubich}
\\
Different choices for $\mathcal{K}$ have been investigated in
\cite{lubichQuantumClassicalMolecular2008} together with the related
computational challenges.
A numerical scheme (order...) based on the splitting method 
for solving the system of equations 
\eqref{hagedorn:hagedorn_dynamics:parameters:evolution:q} -
\eqref{hagedorn:hagedorn_dynamics:parameters:evolution:Q}
can be found in \cite{lubichQuantumClassicalMolecular2008}
while an higher order method in \cite{blanesHighOrderEfficient2020}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Computing the weights for non-quadratic potentials}
\textcolor{red}{Why are we actually doing this? are we sure there is an 
actual advantage?}
In this section we address the computation of the (time dependent) block matrix $\bm{F}$.
Its entries are $d$-dimensional integrals which must be solved at 
each time step \textcolor{red}{Check numerical scheme}
\begin{equation}
  \begin{split}
    \langle 
      W \varphi_l , \varphi_k 
    \rangle
    &= 
    \int_{\mathbb{R}^d}
    W(x) \varphi_l \bar{\varphi}_k dx 
   % \\
   % &=
   % \int_{\mathbb{R}^d}
   % W(x) \varphi_l \bar{\varphi}_k dx 
  \end{split}
\end{equation}
%\begin{itemize}
%  \item Surely we can recycle the sampled points at time 
%    zero since we can just translate the Gaussian in the integrand
%    from which we are sampling from to $\bm{q} = 0$ (and off course 
%    the translation in the potential term)
%  \item Since the time dependence of the integral appears in the integrand 
%    only in the parameter set (for non time dependent potentials), 
%    we can also morph the sampled points according to how the 
%    covariance matrix evolves in time...?
%  \item We still obviously need evaluation of the potential at those 
%    points but as far as the sampling goes it can be done only once...?
%  \item Still for the potential you could also recycle the evaluation 
%    for neighbouring times?
%  \item How can it be that Monte Carlo is dimension independent but QMC 
%    is dimension dependent but nonetheless achieves better convergence? 
%    See effective dimension in \cite{wangEffectiveDimensionQuasiMonte2003} 
%\end{itemize}}
%\textcolor{red}{Is there any way to comment 
%on} $\frac{d}{dt}\langle \varphi_k, W \varphi_l  \rangle$ - all it is 
%changing are the parameters of the wavepackets - translation in position space 
%and momentum space and dilation/contraction. One could imagine recycling 
%the sampled points for neighbouring times? or better if I know, how the 
%integral involving the Gaussian evolves, can I say anything about the 
%evolution of the higher order moments. recycling the sample points since 
%you would also consider tranlating the function to zero, and then simply 
%apply a linear tranformation to the sampled points to account for the 
%spread of the wavepacket...? Can I not apply this on the simple resulting 
%integral...? I do not think so as you would have already evaluated the integrand?
%whose numerical implementation 
%for this algorithm can soon get out of hand. 
%\textcolor{red}{What is the best that one can hope for? How would it scale 
%with the dimension...? Is Monte Carlo independent of the dimension...?
%would that mean I could use the same number of points independent of the dimension?#
%what if I do integration and then differentiation with Monte Carlo - is that 
%justified?}
%\\
%\\
In \cite{bourquinNumericalAlgorithmsSemiclassical2017}
the evaluation of these integrals has been addressed through (sparse) 
quadrature methods 
%(what about QMC?)
%whose computational complexity is still exponential in nature \textcolor{red}{?}
%\textcolor{red}{But why? Is there a reason why quadrature methods would be better 
%in this case and MC methods?}
%\textcolor{red}{what about you solve the d-dimensional gaussian integral - 
%what can you say about the derivatives for the higher order terms...?}
%\\
We investigate alternative numerical (and asymptotic) integration 
methods. 
Firstly, by making use of the recursive relation (...) we reduce the evaluation of the integrals 
to the computation of $\bm{F}_{00}$ and its higher order moments. This should not 
come as a surprise since the Hagedorn wavepackets are polynomials multiplied by a Gaussians. 
Let us re-write (ref recursive relation) as follows 
\textcolor{red}{At some 
point I will consider translating everything to the origin}
\begin{equation}
  \left(\sqrt{k_j + 1 } 
  \varphi^\epsilon_{k + \langle j \rangle} \right)_{j=1}^d&=
  \sqrt{\frac{2}{\epsilon}}\bm{Q^{-1}}
  \Big( (\bm{x} - \bm{q})_j \varphi_k^\epsilon \Big)_{j=1}^d 
  -
  \bm{Q^{-1}}\bm{\overline{Q}}
  \left(\sqrt{k_j} \varphi^\epsilon_{k - \langle j \rangle } \right)_{j=1}^d
\end{equation}
Let $\bm{K}$
denote the diagonal matrix with diagonal entries 
$\bm{K}_{jj} = k_j$ for $j \in \{1,...,d\}$.
Then, multiplying each side of the equality by 
$(\bm{K} + \bm{I}_d)^{-\frac{1}{2}}$ yields 
\begin{equation}
  \begin{split}
  \left( 
  \varphi^\epsilon_{k + \langle j \rangle} \right)_{j=1}^d
  =&
  \sqrt{\frac{2}{\epsilon}}
  (\bm{K} + \bm{I}_d)^{-\frac{1}{2}}\bm{Q^{-1}}
  \Big( (\bm{x} - \bm{q})_j \varphi_k^\epsilon \Big)_{j=1}^d 
  +
  \\
  &-
  (\bm{K} + \bm{I}_d)^{-\frac{1}{2}}
  \bm{Q^{-1}}\bm{\overline{Q}}
  \bm{K}^{\frac{1}{2}}
  \left( \varphi^\epsilon_{k - \langle j \rangle } \right)_{j=1}^d
  \end{split}
\end{equation}
Letting $\bm{A} = \sqrt{\frac{2}{\epsilon}}
(\bm{K} + \bm{I}_d)^{-\frac{1}{2}}\bm{Q}^{-1},
\bm{B} = (\bm{K} + \bm{I}_d)^{-\frac{1}{2}}
          \bm{Q}^{-1}\overline{\bm{Q}}
          \bm{K}^{\frac{1}{2}}$
we can re-write the above expression more coincisely as
\begin{equation}
  \begin{split}
    \Big(\varphi^\epsilon_{k + \langle j \rangle}\Big)_{j=1}^d
    =
    \bm{A} \Big( 
      (\bm{x} - \bm{q})_{j}\varphi^\epsilon_k
    \Big)_{j=1}^d
    - \bm{B} \Big(
      \varphi^\epsilon_{k - \langle j  \rangle}
      \Big)_{j=1}^d
  \end{split}
  \label{hag:dynamics:recurrence:relation:neat}
\end{equation}
Multiplying both sides by $W \overline{\varphi_l}$ 
(a scalar valued function) and 
integrating over $\mathbb{R}^d$ yields 
\begin{equation}
  \begin{split}
    \Big(
    \langle 
      \varphi^\epsilon_{k + \langle j \rangle}
      , W \varphi^\epsilon_l \rangle
    \Big)_{j=1}^d
    =
    \bm{A} \Big( 
      \langle (\bm{x} - \bm{q})_{j}\varphi^\epsilon_k
     , W \varphi^\epsilon_l \rangle
    \Big)_{j=1}^d
    - \bm{B} \Big(
      \langle 
      \varphi^\epsilon_{k - \langle j  \rangle}
      , W \varphi^\epsilon_l \rangle  
    \Big)_{j=1}^d
  \end{split}
  \label{hag:dynamics:recurrence:relation:inner:product}
\end{equation}
Hence, in order to compute
$\langle \varphi^\epsilon_{k + \langle j \rangle}, W \varphi^\epsilon_l  \rangle$ 
we need the higher order moment of the previous Hagedorn wavepacket
$\langle (\bm{x} - \bm{q})_j \varphi^\epsilon_{k}, W \varphi^\epsilon_l \rangle $.
In a similar manner, we can derive a recurrence relation for these higher order terms.
By defining the diagonal matrix $\bm{Y}$ 
with entries $\bm{Y}_{jj} = (\bm{x} - \bm{q})_j$
and multiplying both sides of equation 
\eqref{hag:dynamics:recurrence:relation:neat} gives 
\begin{equation}
  \begin{split}
    \bm{Y}^p\Big(\varphi^\epsilon_{k + \langle j \rangle}\Big)_{j=1}^d
    =
    \bm{Y}^p\bm{A} \Big( 
      (\bm{x} - \bm{q})_{j}\varphi^\epsilon_k
    \Big)_{j=1}^d
    - \bm{Y}^p\bm{B} \Big(
      \varphi^\epsilon_{k - \langle j  \rangle}
      \Big)_{j=1}^d
  \end{split}
\end{equation}
The diagonal matrix $\bm{Y}^p$ does not commute with 
$\bm{A}$ unless the latter is also diagonal and so we have
that the higher order moments depend on the higher order 
cross term moments
\begin{equation}
  \begin{split}
    \Big((\bm{x} - \bm{q})_j^p &
    \varphi^\epsilon_{k + \langle j \rangle}\Big)_{j=1}^d
    =
    \bm{Y}^p
    \Big(
      \sum_{i=1}^d
     \bm{A}_{j,i} 
     (\bm{x} - \bm{q})_{i}\varphi^\epsilon_k
    \Big)_{j=1}^d
    - \bm{Y}^p \Big(
      \sum_{i=1}^d
      \bm{B}_{j,i}
      \varphi^\epsilon_{k - \langle i  \rangle}
      \Big)_{j=1}^d
      \\
    &= 
    \Big(
      \sum_{i=1}^d
     \bm{A}_{j,i} 
     (\bm{x} - \bm{q})^p_j(\bm{x} - \bm{q})_{i}\varphi_k
    \Big)_{j=1}^d
    - \Big(
      \sum_{i=1}^d
      \bm{B}_{j,i}
      (\bm{x}-\bm{q})_j^p
      \varphi_{k - \langle i  \rangle}
      \Big)_{j=1}^d
  \end{split}
\end{equation}
Now, repeating the same process as before, 
multiplying by the scalar $W\overline{\varphi_l}$
on both sides and integrating over $\mathbb{R}^d$ 
yields 
\begin{equation}
  \begin{split}
    &\Big(
      \langle (\bm{x} - \bm{q})_j^p 
    \varphi_{k + \langle j \rangle},
    W \varphi_l \rangle
  \Big)_{j=1}^d
    =
    \\
      =&
    \Big(
      \sum_{i=1}^d
     \bm{A}_{j,i} 
     \langle (\bm{x} - \bm{q})^p_j(\bm{x} - \bm{q})_{i}\varphi_k, 
    W \varphi_l \rangle
    \Big)_{j=1}^d
    - \Big(
      \sum_{i=1}^d
      \bm{B}_{j,i}
      \langle 
      (\bm{x} - \bm{q})_j^p
      \varphi_{k - \langle i  \rangle}
      , W \varphi_l \rangle
      \Big)_{j=1}^d
  \end{split}
  \label{hag:dynamics:recurrence:relation:inner:product:p}
\end{equation}
which now leads to finding an additional recurrence relation 
for the cross terms/moments. 
Note that equation \eqref{hag:dynamics:recurrence:relation:inner:product}
is just equation \eqref{hag:dynamics:recurrence:relation:inner:product:p} 
with $p=0$. We can write out the general expression. Letting 
$\alpha \in \mathbb{N}^d$, we then have 
\begin{equation}
  \begin{split}
    &\left(
    \left \langle
      (\bm{x} - \bm{q})^{p}_{j}
      \prod_{s=1}^{d} (\bm{x} - \bm{q})^{\alpha_s}_{s} 
      \varphi_{k + \langle j \rangle}, W \varphi_{l}
  \right \rangle
\right)_{j=1}^d
=
\\
    &
    \hspace{2cm}
    =
    \left(
      \sum_{i=1}^d
     \bm{A}_{j,i} 
     \left \langle 
     (\bm{x} - \bm{q})^p_j
     \prod_{s=1}^{d} (\bm{x} - \bm{q})^{\alpha_s}_{s} 
     (\bm{x} - \bm{q})_{i}\varphi_k,
     W \varphi_l \right \rangle
    \right)_{j=1}^d +
    \\
    &
    \hspace{2cm}
    - \left(
      \sum_{i=1}^d
      \bm{B}_{j,i}
      \left \langle 
      (\bm{x}-\bm{q})_j^p
      \prod_{s=1}^{d} (\bm{x} - \bm{q})^{\alpha_s}_{s} 
      \varphi_{k - \langle i  \rangle}, 
      W \varphi_l \right \rangle
      \right)_{j=1}^d
\end{split}
\end{equation}
%We want to make clear the dependence in the computation of $F_{ij}$ on the 
%other ...terms/moments?\\\\
%For a given index, what other indices do I need?
%To understand this dependence it suffices to work with the indices.
%\\ 
%Is there an easy way I can explain this? A graph? Something else?
%\textbf{Simpler case:} Let $k \in \mathbb{N}^d$ and fix $l = 0_{\mathbb{N}^d}$. 
%Looking at equation bla bla 
%Then the intregral with $k + \langle j \rangle$ requires computation of only 
%the first term in equation ... bla bla ... since the second term 
%will have been already computed since we are doing this recursively.  
%
%\textcolor{blue}{It makes sense just by arguing as them being polynomials, also 
%recall that you would have had computed already the second term}
%\textcolor{red}{and then what you want to say is that for a given index $\alpha$, 
%what cross terms do you need to re-compute, which ones you need to recycle and so on}
%\textcolor{red}{I wonder if we can think of the algorithm just in terms of indeces then}
Note that we have kept $l$ fixed above, the reason being that 
we can use the conjugate symmetry property to fill in the 
other entries.
This is to be argued better but ultimately, it should be 
clear that we can construct the block matrix $\bm{F}$ from 
knowledge of $\bm{F}_{00}$ and its higher order terms alone.
\end{document}
